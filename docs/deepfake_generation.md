# Deepfake Video Generation Documentation

**Project:** Assignment 09 - Deepfake Detection
**Phase:** 2 - Video Generation
**Date:** December 27, 2025
**Status:** To Be Completed

---

## Table of Contents
1. [Overview](#overview)
2. [Ethical Statement](#ethical-statement)
3. [Tool Selection](#tool-selection)
4. [Generation Process](#generation-process)
5. [Source Materials](#source-materials)
6. [Technical Specifications](#technical-specifications)
7. [Observations and Limitations](#observations-and-limitations)
8. [Verification Steps](#verification-steps)
9. [Repository Integration](#repository-integration)

---

## Overview

This document describes the process of generating a deepfake video from a still image using **Google Flow (Inframe option)** for academic testing purposes within the deepfake detection system project.

**Purpose**: Create a controlled deepfake sample to evaluate the LLM-based detection system's ability to identify synthetic media and explain its reasoning.

**Generation Date**: _[To be filled]_
**Generated By**: _[To be filled]_

---

## Ethical Statement

### Academic Use Only

This deepfake video is generated exclusively for:
- Educational purposes within an academic assignment
- Research and development of deepfake detection methodologies
- Demonstrating LLM-based analysis capabilities

### Ethical Guidelines Followed

1. **No Malicious Intent**: The deepfake is not created to deceive, defame, or harm any individual
2. **No Public Distribution**: The generated content will not be distributed outside the academic context
3. **Clear Labeling**: All deepfake content is clearly labeled and documented
4. **Consent Consideration**:
   - If using an image of a real person, appropriate permissions should be obtained or public domain/licensed images used
   - If using own image or synthetic face, this is documented
5. **Responsible Use**: The technology is used to understand and combat malicious deepfakes, not to create them

### Legal Compliance

This work complies with:
- Academic integrity policies
- Fair use provisions for educational research
- Applicable laws regarding synthetic media

**Declaration**: The deepfake video generated as part of this assignment is for academic evaluation only and will not be used for any deceptive or harmful purposes.

---

## Tool Selection

### Primary Tool: Google Flow (Inframe Option)

**Tool Name**: Google Flow
**Feature Used**: Inframe
**Access Method**: _[To be filled: e.g., web interface, API, desktop application]_
**Version/Date**: _[To be filled]_

### Why Google Flow Inframe?

Google Flow's Inframe feature is selected because:
1. **Assignment Requirement**: Explicitly specified in the assignment guidelines
2. **Image-to-Video Generation**: Capable of animating a single still image
3. **Accessibility**: _[To be filled: Available for academic use]_
4. **Quality**: _[To be filled: Expected to produce realistic deepfakes suitable for testing]_

### Alternative Tools Considered

_[Optional: List any alternative tools considered and why they were not used]_
- Example: D-ID, Synthesia, DeepFaceLab, etc.

---

## Generation Process

### Step-by-Step Instructions

This section documents the exact process followed to generate the deepfake video.

#### Step 1: Source Image Selection
_[To be filled]_

**Actions taken**:
- Selected image: `[filename]`
- Image source: _[Public domain / Own photo / Licensed image / Synthetic]_
- Image resolution: _[e.g., 1920x1080]_
- Subject description: _[e.g., Human face, frontal view, neutral expression]_

**Rationale for selection**:
- _[Why this particular image was chosen]_
- _[Characteristics that make it suitable for deepfake generation]_

#### Step 2: Access Google Flow Inframe
_[To be filled]_

**Actions taken**:
- Accessed tool via: _[URL or application]_
- Login/authentication: _[If applicable]_
- Interface version: _[If available]_

#### Step 3: Configure Generation Settings
_[To be filled]_

**Settings used**:
```
Duration: [e.g., 5 seconds]
Animation Type: [e.g., talking, moving, expression change]
Voice/Audio: [Yes/No, if applicable]
Quality Settings: [e.g., HD, 1080p]
Frame Rate: [e.g., 30 fps]
Additional Parameters: [Any other relevant settings]
```

**Settings rationale**:
- _[Why these settings were chosen]_
- _[Expected characteristics of output]_

#### Step 4: Generate Video
_[To be filled]_

**Actions taken**:
- Initiated generation: _[Date/time]_
- Processing time: _[Duration]_
- Any intermediate steps: _[If applicable]_

#### Step 5: Download and Verify
_[To be filled]_

**Actions taken**:
- Downloaded file: `[filename]`
- Verified playback: _[Yes/No]_
- Checked file integrity: _[Yes/No]_

---

## Source Materials

### Source Image

**Filename**: _[To be filled]_
**Location in Repository**: `data/videos/fake/source_image.jpg` _(or similar)_

**Image Details**:
- **Resolution**: _[e.g., 1920x1080 pixels]_
- **Format**: _[e.g., JPEG, PNG]_
- **File Size**: _[e.g., 2.5 MB]_
- **Source**: _[Description of where/how the image was obtained]_
- **License/Rights**: _[Public domain, Creative Commons, Own creation, etc.]_

**Subject Description**:
- **Content**: _[e.g., Adult human face, frontal view]_
- **Lighting**: _[e.g., Well-lit, neutral background]_
- **Quality**: _[e.g., High resolution, clear features]_
- **Notable Features**: _[e.g., Direct eye contact with camera, neutral expression]_

**Why This Image?**:
- _[Explanation of selection criteria]_
- _[Expected deepfake characteristics]_

### Audio (If Applicable)

**Audio Source**: _[None / Generated / Recorded]_
**Details**: _[If audio was used in the deepfake generation]_

---

## Technical Specifications

### Generated Deepfake Video

**Filename**: `deepfake_inframe_v1.mp4`
**Location**: `data/videos/fake/deepfake_inframe_v1.mp4`

**Video Metadata**:
```
Format: MP4
Codec: [e.g., H.264]
Resolution: [e.g., 1920x1080]
Duration: [e.g., 5.2 seconds]
Frame Rate: [e.g., 30 fps]
Bitrate: [e.g., 5000 kbps]
File Size: [e.g., 3.2 MB]
Audio: [Yes/No, codec if applicable]
```

**Generation Metadata**:
```
Tool: Google Flow Inframe
Generation Date: [Date]
Processing Time: [Duration]
Version/Model: [If available]
Settings Hash: [If trackable]
```

### Verification Commands

To verify video metadata, use:
```bash
ffprobe -v quiet -print_format json -show_format -show_streams data/videos/fake/deepfake_inframe_v1.mp4
```

To extract a sample frame:
```bash
ffmpeg -i data/videos/fake/deepfake_inframe_v1.mp4 -ss 00:00:02 -vframes 1 data/videos/fake/deepfake_sample_frame.jpg
```

---

## Observations and Limitations

### Visual Characteristics Observed

_[To be filled after generation]_

**Anticipated deepfake artifacts**:
- _[e.g., Facial smoothing, unnatural eye movement]_
- _[e.g., Lighting inconsistencies]_
- _[e.g., Motion artifacts around face boundaries]_

**Realism assessment**:
- _[Subjective evaluation of how realistic the deepfake appears]_
- _[Areas that appear convincing vs. suspicious]_

### Generation Limitations Encountered

_[To be filled]_

**Technical limitations**:
- _[e.g., Limited control over animation style]_
- _[e.g., Fixed duration constraints]_
- _[e.g., Resolution limitations]_

**Quality limitations**:
- _[e.g., Visible artifacts in certain frames]_
- _[e.g., Unnatural movements]_
- _[e.g., Background issues]_

**Process limitations**:
- _[e.g., Processing time constraints]_
- _[e.g., Limited parameter customization]_
- _[e.g., File size restrictions]_

### Suitability for Detection Testing

**Expected detectability**:
- _[Assessment of whether the deepfake has sufficient artifacts to be detected]_
- _[Specific cues that the LLM-based detector should identify]_

**Testing value**:
- _[How this deepfake serves the project goals]_
- _[What aspects of detection it will help evaluate]_

---

## Verification Steps

### Manual Visual Inspection

_[To be filled after generation]_

**Inspection checklist**:
- [ ] Video plays correctly in standard media players
- [ ] Duration matches expected length
- [ ] Resolution is adequate for analysis
- [ ] Audio (if applicable) is synchronized
- [ ] No corruption or encoding errors
- [ ] Visible deepfake artifacts present (for testing purposes)

**Observations**:
- _[Notes from manual inspection]_

### Technical Verification

_[To be filled after generation]_

**File integrity**:
```bash
# Check file is valid MP4
file data/videos/fake/deepfake_inframe_v1.mp4

# Verify video metadata
ffprobe data/videos/fake/deepfake_inframe_v1.mp4
```

**Expected output**:
- Valid MP4 container
- Video and audio streams present (if applicable)
- No errors or warnings

### Comparison with Source

_[To be filled]_

**Source vs. Generated comparison**:
- _[How the deepfake compares to the original still image]_
- _[What transformations are visible]_
- _[Quality preservation or degradation]_

---

## Repository Integration

### File Organization

Generated files stored in the repository:

```
data/videos/fake/
├── deepfake_inframe_v1.mp4          # Primary generated deepfake
├── source_image.jpg                  # Original still image used
├── deepfake_sample_frame.jpg         # Sample frame for documentation
└── README.md                         # Video metadata and descriptions
```

### File Naming Convention

**Pattern**: `deepfake_[tool]_v[version].mp4`

- `deepfake`: Indicates synthetic content
- `inframe`: Specifies the tool/method used
- `v1`: Version number (in case multiple attempts are made)

### Documentation Files

Related documentation:
- `docs/deepfake_generation.md` - This document
- `data/videos/fake/README.md` - Video metadata summary

---

## Next Steps

After completing deepfake generation:

1. **Phase 2 Completion**:
   - [ ] Fill in all _[To be filled]_ sections in this document
   - [ ] Add generated video to repository
   - [ ] Add source image to repository
   - [ ] Create `data/videos/fake/README.md` with video metadata
   - [ ] Commit and push all changes

2. **Prepare for Phase 3**:
   - [ ] Acquire or create authentic real video
   - [ ] Store real video in `data/videos/real/`
   - [ ] Document real video source and characteristics

3. **Ready for Detection Development**:
   - [ ] Verify both test videos (fake and real) are in repository
   - [ ] Ensure videos meet technical specifications from PRD
   - [ ] Proceed to Phase 3: Core Development

---

## Appendix A: Google Flow Inframe Instructions

### How to Generate a Deepfake Using Google Flow Inframe

_[To be filled with step-by-step guide based on actual experience]_

**Prerequisites**:
- _[e.g., Google account, browser requirements, etc.]_

**Access**:
1. _[URL or application to access]_
2. _[Login instructions]_

**Generation Process**:
1. _[Upload image instructions]_
2. _[Parameter selection]_
3. _[Generation initiation]_
4. _[Download instructions]_

**Tips and Best Practices**:
- _[Based on experience with the tool]_

---

## Appendix B: Troubleshooting

### Common Issues and Solutions

_[To be filled based on experience]_

**Issue**: _[Description]_
**Solution**: _[Resolution steps]_

**Issue**: _[Description]_
**Solution**: _[Resolution steps]_

---

## Appendix C: References

### Google Flow Documentation
- _[Official documentation links]_
- _[Tutorials or guides used]_

### Deepfake Technology Background
- _[Academic papers or articles referenced]_
- _[Technical resources consulted]_

### Ethical Guidelines
- IEEE Ethics in AI
- ACM Code of Ethics
- University academic integrity policies
- _[Any other relevant ethical frameworks]_

---

## Document History

| Version | Date | Author | Changes |
|---------|------|--------|---------|
| 1.0 | 2025-12-27 | Initial Author | Created documentation template |
| 1.1 | _[To be filled]_ | _[Name]_ | Completed after video generation |

---

**End of Deepfake Generation Documentation**

---

## IMPORTANT: Instructions for Completion

**This is a template document. To complete Phase 2, you need to**:

1. **Generate the deepfake video** using Google Flow (Inframe option)
2. **Fill in all sections** marked with _[To be filled]_
3. **Add the generated video** to `data/videos/fake/deepfake_inframe_v1.mp4`
4. **Add the source image** to `data/videos/fake/source_image.jpg`
5. **Update this document** with actual details from your generation process
6. **Create** `data/videos/fake/README.md` with video descriptions
7. **Commit and push** all changes to GitHub

Once completed, this document will serve as a complete record of the deepfake generation process for the assignment evaluation.
